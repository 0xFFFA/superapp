#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–æ—Å—Ç–æ–µ RAG –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø–æ –≥–æ—Ä–Ω–æ–º—É –¥–µ–ª—É
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç TF-IDF –∏ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
"""

import json
import math
import re
from collections import Counter
from flask import Flask, render_template, request, jsonify
import os

class SimpleRAG:
    """–ü—Ä–æ—Å—Ç–æ–π RAG —Å TF-IDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π"""
    
    def __init__(self, data_file):
        self.data_file = data_file
        self.qa_pairs = []
        self.vocabulary = set()
        self.tf_idf_matrix = []
        self.idf_scores = {}
        self.load_data()
        self.build_index()
    
    def load_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        
        with open(self.data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.qa_pairs = data['qa_pairs']
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.qa_pairs)} –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç")
    
    def preprocess_text(self, text):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è"""
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        text = text.lower()
        
        # –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        words = text.split()
        
        # –£–¥–∞–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤)
        words = [word for word in words if len(word) >= 3]
        
        return words
    
    def build_index(self):
        """–°—Ç—Ä–æ–∏—Ç TF-IDF –∏–Ω–¥–µ–∫—Å –¥–ª—è –ø–æ–∏—Å–∫–∞"""
        print("üîç –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è
        all_texts = []
        for qa in self.qa_pairs:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
            combined_text = f"{qa['question']} {qa['answer']}"
            processed_text = self.preprocess_text(combined_text)
            all_texts.append(processed_text)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä—å
            self.vocabulary.update(processed_text)
        
        self.vocabulary = list(self.vocabulary)
        print(f"üìù –°–ª–æ–≤–∞—Ä—å —Å–æ–¥–µ—Ä–∂–∏—Ç {len(self.vocabulary)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤")
        
        # –í—ã—á–∏—Å–ª—è–µ–º IDF –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
        total_docs = len(all_texts)
        for word in self.vocabulary:
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö —ç—Ç–æ —Å–ª–æ–≤–æ
            doc_count = sum(1 for text in all_texts if word in text)
            self.idf_scores[word] = math.log(total_docs / doc_count) if doc_count > 0 else 0
        
        # –í—ã—á–∏—Å–ª—è–µ–º TF-IDF –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        for text in all_texts:
            tf_scores = Counter(text)
            tf_idf_vector = []
            
            for word in self.vocabulary:
                tf = tf_scores.get(word, 0) / len(text) if len(text) > 0 else 0
                idf = self.idf_scores[word]
                tf_idf_vector.append(tf * idf)
            
            self.tf_idf_matrix.append(tf_idf_vector)
        
        print("‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    
    def cosine_similarity(self, vec1, vec2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏"""
        if len(vec1) != len(vec2):
            return 0
        
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        magnitude1 = math.sqrt(sum(a * a for a in vec1))
        magnitude2 = math.sqrt(sum(a * a for a in vec2))
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0
        
        return dot_product / (magnitude1 * magnitude2)
    
    def search(self, query, top_k=5):
        """–ò—â–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –∑–∞–ø—Ä–æ—Å"""
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å
        processed_query = self.preprocess_text(query)
        
        # –°–æ–∑–¥–∞–µ–º TF-IDF –≤–µ–∫—Ç–æ—Ä –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        query_tf = Counter(processed_query)
        query_vector = []
        
        for word in self.vocabulary:
            tf = query_tf.get(word, 0) / len(processed_query) if len(processed_query) > 0 else 0
            idf = self.idf_scores.get(word, 0)
            query_vector.append(tf * idf)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –∫–∞–∂–¥—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        similarities = []
        for i, doc_vector in enumerate(self.tf_idf_matrix):
            similarity = self.cosine_similarity(query_vector, doc_vector)
            similarities.append((i, similarity))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-K —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = []
        for i, (doc_idx, similarity) in enumerate(similarities[:top_k]):
            if similarity > 0:  # –¢–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                qa = self.qa_pairs[doc_idx]
                results.append({
                    'question': qa['question'],
                    'answer': qa['answer'],
                    'similarity': similarity,
                    'rank': i + 1
                })
        
        return results
    
    def generate_answer(self, query, context_limit=3):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        search_results = self.search(query, top_k=context_limit)
        
        if not search_results:
            return {
                'answer': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.",
                'sources': [],
                'confidence': 0.0
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources = []
        answer_parts = []
        
        for result in search_results:
            sources.append({
                'question': result['question'],
                'answer': result['answer'],
                'similarity': result['similarity']
            })
            
            # –ï—Å–ª–∏ —Å—Ö–æ–¥—Å—Ç–≤–æ –≤—ã—Å–æ–∫–æ–µ, –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            if result['similarity'] > 0.1:
                answer_parts.append(result['answer'])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        if answer_parts:
            combined_answer = " ".join(answer_parts[:2])  # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º—É–º 2 –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            confidence = max(result['similarity'] for result in search_results)
        else:
            combined_answer = search_results[0]['answer']
            confidence = search_results[0]['similarity']
        
        return {
            'answer': combined_answer,
            'sources': sources,
            'confidence': confidence
        }

# –°–æ–∑–¥–∞–µ–º Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = Flask(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG —Å–∏—Å—Ç–µ–º—É
rag_system = SimpleRAG('output/base-mining-and-mining-quality.final.json')

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/api/search', methods=['POST'])
def search():
    """API –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤"""
    data = request.get_json()
    query = data.get('query', '')
    
    if not query:
        return jsonify({'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    result = rag_system.generate_answer(query)
    
    return jsonify(result)

@app.route('/api/suggestions', methods=['GET'])
def get_suggestions():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    suggestions = [
        "–ö–∞–∫ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫—Ä–µ–ø–æ—Å—Ç–∏ –ü—Ä–æ—Ç–æ–¥—å—è–∫–æ–Ω–æ–≤–∞?",
        "–ö–∞–∫–∞—è –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–æ–ª—â–∏–Ω–∞ –≤—ã—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è –≤–∑—Ä—ã–≤–Ω—ã—Ö —Ä–∞–±–æ—Ç?",
        "–ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª–∏–Ω–∏—é –ø–∞–¥–µ–Ω–∏—è –ø–ª–∞—Å—Ç–∞?",
        "–ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å —Å–ø–æ—Å–æ–± –∫—Ä–µ–ø–ª–µ–Ω–∏—è –¥–ª—è –≥–æ—Ä–Ω—ã—Ö –≤—ã—Ä–∞–±–æ—Ç–æ–∫?",
        "–ö–∞–∫ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ —à–Ω–µ–∫–æ–≤—É—é –ª–∏–Ω–∏—é?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∏–º–∞–µ–º–æ—Å—Ç–∏ –ø–æ—Ä–æ–¥—ã?",
        "–ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–µ–¥–µ–ª –ø—Ä–æ—á–Ω–æ—Å—Ç–∏ –ø–æ—Ä–æ–¥—ã –Ω–∞ —Ç—Ä–µ–Ω–∏–µ?",
        "–ö–∞–∫ –≤—ã—á–∏—Å–ª–∏—Ç—å —É–≥–æ–ª –ø–∞–¥–µ–Ω–∏—è –ø—Ä–∏ –≥–æ—Ä–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—Ö?"
    ]
    
    return jsonify({'suggestions': suggestions})

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ RAG –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    print("üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π: 326 –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –ø–æ –≥–æ—Ä–Ω–æ–º—É –¥–µ–ª—É")
    print("üåê –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:5000")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —à–∞–±–ª–æ–Ω–æ–≤
    os.makedirs('templates', exist_ok=True)
    
    app.run(debug=True, host='0.0.0.0', port=5000)
