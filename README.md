# üè≠ SuperApp - Industrial AI Trainer

–°–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

## üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö AI-–º–æ–¥–µ–ª–µ–π, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö –∏ –ø–æ–º–æ–≥–∞—Ç—å –∏–Ω–∂–µ–Ω–µ—Ä–∞–º –≤ —Ä–µ—à–µ–Ω–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á.

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
superapp/
‚îú‚îÄ‚îÄ üìÅ app/              # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ pdf_to_qa.py     # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ Q&A
‚îÇ   ‚îú‚îÄ‚îÄ fix_errors.py    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ merge_datasets.py # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ train_qlora.py   # QLoRA –æ–±—É—á–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ continue_training.py # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ test_trained_model.py # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ compare_models.py # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ üìÅ input/            # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞—Ç–∞—Å–µ—Ç—ã
‚îú‚îÄ‚îÄ üìÅ output/           # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îú‚îÄ‚îÄ üìÅ models/           # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ üìÅ trained-models/  # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ üìÅ log/              # –õ–æ–≥–∏ —Ä–∞–±–æ—Ç—ã
‚îú‚îÄ‚îÄ requirements.txt     # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îî‚îÄ‚îÄ README.md           # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
git clone https://github.com/0xFFFA/superapp.git
cd superapp
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
```bash
# –°–æ–∑–¥–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è –º–æ–¥–µ–ª–µ–π
mkdir -p models

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å git-lfs –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
sudo apt-get install git-lfs  # Ubuntu/Debian
# –∏–ª–∏
brew install git-lfs          # macOS

git lfs install
```

### 3. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

#### **Qwen 2.5 3B (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–∞—á–∞–ª–∞)**
```bash
# –°–∫–∞—á–∞—Ç—å Qwen –º–æ–¥–µ–ª—å (~6GB)
git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct models/qwen-2.5-3b
```

#### **YandexGPT 5 Lite 8B (–¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)**
```bash
# –°–∫–∞—á–∞—Ç—å Yandex –º–æ–¥–µ–ª—å (~16GB)
git clone https://huggingface.co/yandex/YandexGPT-5-Lite-8B-instruct models/yandex-model
```

#### **–î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏**
```bash
# Mistral 7B
git clone https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2 models/mistral-7b

# Llama 2 7B (—Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é)
huggingface-cli login
git clone https://huggingface.co/meta-llama/Llama-2-7b-chat-hf models/llama2-7b
```

### 4. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
–°–æ–∑–¥–∞–π—Ç–µ JSON —Ñ–∞–π–ª —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
```json
{
  "qa_pairs": [
    {
      "question": "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —à–∞—Ä–æ–≤–∞—è –º–µ–ª—å–Ω–∏—Ü–∞?",
      "answer": "–®–∞—Ä–æ–≤–∞—è –º–µ–ª—å–Ω–∏—Ü–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞ —Å—á–µ—Ç –≤—Ä–∞—â–µ–Ω–∏—è –±–∞—Ä–∞–±–∞–Ω–∞..."
    }
  ]
}
```

### 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
```bash
# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ Qwen –º–æ–¥–µ–ª–∏
python app/train_qlora.py \
    --data output/dataset.json \
    --base-model models/qwen-2.5-3b \
    --output-dir trained-models/model_v1 \
    --epochs 3 \
    --learning-rate 2e-4

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ Yandex –º–æ–¥–µ–ª–∏ (—Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏)
python app/train_qlora.py \
    --data output/dataset.json \
    --base-model models/yandex-model \
    --output-dir trained-models/yandex_v1 \
    --epochs 2 \
    --learning-rate 2e-4 \
    --batch-size 1
```

### 6. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
```bash
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained-models/model_v1
```

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### üéì –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- **QLoRA –æ–±—É—á–µ–Ω–∏–µ** —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- **–ü–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** –Ω–∞ –Ω–æ–≤—ã—Ö –¥–æ–º–µ–Ω–∞—Ö –∑–Ω–∞–Ω–∏–π
- **–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è** –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- **–ê–¥–∞–ø—Ç–∞—Ü–∏—è** –ø–æ–¥ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏

### üîç –ê–Ω–∞–ª–∏–∑ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** –¥–æ –∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
- **–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞** –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
- **–í–∞–ª–∏–¥–∞—Ü–∏—è** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤** –≤ —Ñ–æ—Ä–º–∞—Ç–µ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
- **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è** –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
- **–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

## üìã –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ Q&A
```bash
python app/pdf_to_qa.py input/document.pdf -o output/dataset.json -m qwen2.5:3b -q 5
```

### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
```bash
python app/train_qlora.py \
    --data output/dataset.json \
    --base-model models/qwen-2.5-3b \
    --output-dir trained-models/model_v1 \
    --epochs 3 \
    --learning-rate 2e-4
```

### –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
```bash
python app/continue_training.py \
    --data input/new_data.json \
    --base-model models/qwen-2.5-3b \
    --trained-model trained-models/model_v1 \
    --output-dir trained-models/model_v2
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
```bash
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained-models/model_v1 \
    --questions "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞—Å–æ—Å?" "–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–∏—Å–ø–µ—Ä–≥–∞—Ç–æ—Ä?"
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

### üì¶ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

#### **–ü—É–±–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)**
- **Qwen 2.5 3B** - `Qwen/Qwen2.5-3B-Instruct` (~6GB)
- **Mistral 7B** - `mistralai/Mistral-7B-Instruct-v0.2` (~14GB)
- **YandexGPT 5 Lite 8B** - `yandex/YandexGPT-5-Lite-8B-instruct` (~16GB)

#### **–ú–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π**
- **Llama 2** - `meta-llama/Llama-2-7b-chat-hf` (—Ç—Ä–µ–±—É–µ—Ç —Ç–æ–∫–µ–Ω)
- **CodeLlama** - `codellama/CodeLlama-7b-Instruct-hf`

### üöÄ –ë—ã—Å—Ç—Ä–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π

#### **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**
```bash
# –°–∫—Ä–∏–ø—Ç –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
./install_models.sh
```

#### **–†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**
```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å git-lfs
sudo apt-get install git-lfs
git lfs install

# 2. –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏
git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct models/qwen-2.5-3b
git clone https://huggingface.co/yandex/YandexGPT-5-Lite-8B-instruct models/yandex-model

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É
ls -la models/
```

### üíæ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∏—Å–∫–æ–≤–æ–º—É –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π GPU |
|--------|--------|-------------------|
| Qwen 2.5 3B | ~6GB | 8GB+ |
| YandexGPT 5 Lite 8B | ~16GB | 16GB+ |
| Mistral 7B | ~14GB | 16GB+ |
| Llama 2 7B | ~13GB | 16GB+ |

### üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤

#### **–ú–æ—â–Ω—ã–π —Å–µ—Ä–≤–µ—Ä (GPU 16GB+)**
```bash
# –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –º–æ–¥–µ–ª–∏
python app/train_qlora.py \
    --base-model models/yandex-model \
    --batch-size 4 \
    --lora-r 16
```

#### **–°—Ä–µ–¥–Ω–∏–π —Å–µ—Ä–≤–µ—Ä (GPU 8GB)**
```bash
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Qwen 2.5 3B
python app/train_qlora.py \
    --base-model models/qwen-2.5-3b \
    --batch-size 2 \
    --lora-r 8
```

#### **–°–ª–∞–±—ã–π —Å–µ—Ä–≤–µ—Ä (CPU —Ç–æ–ª—å–∫–æ)**
```bash
# –û—Ç–∫–ª—é—á–∏—Ç—å GPU
export CUDA_VISIBLE_DEVICES=""

python app/train_qlora.py \
    --base-model models/qwen-2.5-3b \
    --batch-size 1 \
    --lora-r 4 \
    --epochs 1
```

## ‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Python** 3.8+
- **PyTorch** 2.0+
- **Transformers** 4.30+
- **PEFT** (Parameter-Efficient Fine-Tuning)
- **Git LFS** –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
- **GPU** —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- **RAM** –º–∏–Ω–∏–º—É–º 16GB
- **–î–∏—Å–∫** –º–∏–Ω–∏–º—É–º 50GB –¥–ª—è –º–æ–¥–µ–ª–µ–π

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
- **LoRA Rank**: 4-64 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 16)
- **Learning Rate**: 1e-5 –¥–æ 2e-4
- **Batch Size**: 1-16 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç GPU)
- **Epochs**: 1-10 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏)

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ –º–æ–¥–µ–ª–∏

#### **Qwen 2.5 3B**
```bash
--epochs 3 --learning-rate 2e-4 --batch-size 2 --lora-r 16
```

#### **YandexGPT 5 Lite 8B**
```bash
--epochs 2 --learning-rate 1e-4 --batch-size 1 --lora-r 8
```

#### **Mistral 7B**
```bash
--epochs 2 --learning-rate 1e-4 --batch-size 1 --lora-r 8
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

- **–ö–æ–Ω—Å–æ–ª—å–Ω—ã–µ –ª–æ–≥–∏** –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- **–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** –º–æ–¥–µ–ª–µ–π –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤
- **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞** –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU**
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å batch-size –∏ lora-r
python app/train_qlora.py --batch-size 1 --lora-r 4

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU
export CUDA_VISIBLE_DEVICES=""
```

#### **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM**
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
python app/train_qlora.py --epochs 1 --batch-size 1 --lora-r 4
```

#### **–û—à–∏–±–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å git-lfs
git lfs install

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ Hugging Face
curl -I https://huggingface.co/Qwen/Qwen2.5-3B-Instruct
```

#### **–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU: `nvidia-smi`
- –£–≤–µ–ª–∏—á—å—Ç–µ batch-size –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –º–æ—â–Ω—ã–π —Å–µ—Ä–≤–µ—Ä

### –ü–æ–¥–¥–µ—Ä–∂–∫–∞
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ –≤–µ—Ç–∫—É –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT.

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- Hugging Face –∑–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Transformers –∏ PEFT
- Microsoft –∑–∞ LoRA –º–µ—Ç–æ–¥
- Alibaba Cloud –∑–∞ –º–æ–¥–µ–ª—å Qwen
- Yandex –∑–∞ –º–æ–¥–µ–ª—å YandexGPT
- –°–æ–æ–±—â–µ—Å—Ç–≤–æ open-source –∑–∞ –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ

---

**SuperApp** - –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–µ–µ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å –ø–æ–º–æ—â—å—é AI! üöÄ
