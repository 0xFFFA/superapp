# üè≠ SuperApp - Industrial AI Trainer

–°–∏—Å—Ç–µ–º–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.

## üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö AI-–º–æ–¥–µ–ª–µ–π, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö –∏ –ø–æ–º–æ–≥–∞—Ç—å –∏–Ω–∂–µ–Ω–µ—Ä–∞–º –≤ —Ä–µ—à–µ–Ω–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á.

## ‚ú® –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- üîÑ **–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ Q&A** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- üéì **QLoRA –æ–±—É—á–µ–Ω–∏–µ** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ fine-tuning —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏
- üîÑ **–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è** - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- üìä **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** - –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è
- üõ†Ô∏è **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- üìà **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

1. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞**: `sudo apt update && sudo apt install git && git clone https://github.com/0xFFFA/superapp.git`
2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞**: `cd superapp && python3 -m venv venv && source venv/bin/activate && pip install -r requirements.txt`
3. **–ú–æ–¥–µ–ª–∏**: `mkdir -p models && cd models && git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct qwen-2.5-3b`
4. **Ollama**: `curl -fsSL https://ollama.com/install.sh | sh && ollama pull qwen2.5:3b`
5. **–û–±—É—á–µ–Ω–∏–µ**: `python app/train_qlora.py --data output/dataset.json --base-model models/qwen-2.5-3b --output-dir trained_model/v1`

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
superapp/
‚îú‚îÄ‚îÄ üìÅ app/              # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ pdf_to_qa.py     # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ Q&A
‚îÇ   ‚îú‚îÄ‚îÄ fix_errors.py    # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ merge_datasets.py # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ train_qlora.py   # QLoRA –æ–±—É—á–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ continue_training.py # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ test_trained_model.py # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ compare_models.py # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îú‚îÄ‚îÄ üìÅ input/            # –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –¥–∞—Ç–∞—Å–µ—Ç—ã
‚îú‚îÄ‚îÄ üìÅ output/           # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏
‚îú‚îÄ‚îÄ üìÅ models/           # –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ üìÅ trained-models/  # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ üìÅ log/              # –õ–æ–≥–∏ —Ä–∞–±–æ—Ç—ã
‚îú‚îÄ‚îÄ requirements.txt     # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îî‚îÄ‚îÄ README.md           # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

## üöÄ –ü–æ–ª–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã
```bash
# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
sudo apt update
sudo apt upgrade

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Git
sudo apt install git

# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/0xFFFA/superapp.git
cd superapp
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python –∏ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏ Python)
sudo apt install python3.12-venv  # –î–ª—è Python 3.12
# –∏–ª–∏
sudo apt install python3.10-venv  # –î–ª—è Python 3.10

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python3 -m venv venv
source venv/bin/activate

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements.txt
```

### 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π
mkdir -p models
cd models

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ git-lfs –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
sudo apt-get update
sudo apt-get install git-lfs
git lfs install

# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Qwen 2.5 3B
git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct qwen-2.5-3b
cd ..
```

### 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Ollama
curl -fsSL https://ollama.com/install.sh | sh

# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è Ollama
ollama pull qwen2.5:3b
```

### 5. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA (–µ—Å–ª–∏ –µ—Å—Ç—å GPU)
```bash
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –¥—Ä–∞–π–≤–µ—Ä–æ–≤
sudo ubuntu-drivers install --gpgpu

# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã
sudo reboot

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥—Ä–∞–π–≤–µ—Ä–æ–≤
nvidia-smi
```

### 6. –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤
```bash
mkdir -p output
mkdir -p input
```

## üìö –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ PDF
```bash
# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
source venv/bin/activate

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ —Ñ–æ—Ä–º–∞—Ç –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
python app/pdf_to_qa.py input/ballmill-part3.pdf \
    -o output/ballmill-part3.json \
    -m qwen2.5:3b \
    -q 7 \
    --ollama-url http://localhost:11434
```

### 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ)
```bash
# –ï—Å–ª–∏ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ output –ø–æ—è–≤–∏–ª—Å—è —Ñ–∞–π–ª ballmill-part3.err
python app/fix_errors.py output/ballmill-part3.err \
    -o output/ballmill-part3.mid
```

### 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
```bash
# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ json –∏ mid –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
python app/merge_datasets.py \
    output/ballmill-part3.json \
    output/ballmill-part3.mid \
    -o output/ballmill-part3.final.json
```

### 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
```bash
# –î–ª—è —Å–∏—Å—Ç–µ–º –±–µ–∑ GPU –∏–ª–∏ —Å–æ —Å–ª–∞–±—ã–º GPU
export CUDA_VISIBLE_DEVICES=""

# –û–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python app/train_qlora.py \
    --data output/ballmill-part3.final.json \
    --base-model models/qwen-2.5-3b \
    --output-dir trained_model/v1 \
    --learning-rate 1e-4 \
    --epochs 5 \
    --batch-size 2 \
    --lora-r 32 \
    --device cuda
```

### 5. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
```bash
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–µ–π
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --questions \
        "–ß—Ç–æ —Ç–∞–∫–æ–µ —à–∞—Ä–æ–≤–∞—è –º–µ–ª—å–Ω–∏—Ü–∞?" \
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∏—Å–ø–µ—Ä–≥–∞—Ç–æ—Ä?" \
        "–ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏–∑–º–µ–ª—å—á–µ–Ω–∏—è?"
```

### 6. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
```bash
# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
python app/continue_training.py \
    --data output/new_dataset.json \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --output-dir trained_model/v2 \
    --learning-rate 5e-5 \
    --epochs 2 \
    --batch-size 2 \
    --lora-r 16 \
    --device cuda
```

## üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### üéì –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- **QLoRA –æ–±—É—á–µ–Ω–∏–µ** —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- **–ü–µ—Ä–≤–∏—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** –Ω–∞ –Ω–æ–≤—ã—Ö –¥–æ–º–µ–Ω–∞—Ö –∑–Ω–∞–Ω–∏–π
- **–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è** –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- **–ê–¥–∞–ø—Ç–∞—Ü–∏—è** –ø–æ–¥ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏

### üîç –ê–Ω–∞–ª–∏–∑ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π** –¥–æ –∏ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
- **–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞** –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã
- **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
- **–í–∞–ª–∏–¥–∞—Ü–∏—è** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤** –≤ —Ñ–æ—Ä–º–∞—Ç–µ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
- **–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è** –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
- **–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

## üìã –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ Q&A
```bash
# –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
python app/pdf_to_qa.py input/document.pdf \
    -o output/dataset.json \
    -m qwen2.5:3b \
    -q 5

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
python app/pdf_to_qa.py input/technical_manual.pdf \
    -o output/manual_qa.json \
    -m qwen2.5:3b \
    -q 10 \
    --ollama-url http://localhost:11434 \
    --chunk-size 3000
```

### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
```bash
# –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
python app/train_qlora.py \
    --data output/dataset.json \
    --base-model models/qwen-2.5-3b \
    --output-dir trained_model/v1_quick \
    --epochs 1 \
    --learning-rate 2e-4 \
    --batch-size 4 \
    --lora-r 8

# –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
python app/train_qlora.py \
    --data output/dataset.json \
    --base-model models/qwen-2.5-3b \
    --output-dir trained_model/v1_quality \
    --epochs 5 \
    --learning-rate 1e-4 \
    --batch-size 2 \
    --lora-r 32
```

### –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
```bash
# –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
python app/continue_training.py \
    --data output/new_data.json \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --output-dir trained_model/v2 \
    --learning-rate 5e-5 \
    --epochs 2

# –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –Ω–æ–≤—ã–π –¥–æ–º–µ–Ω
python app/continue_training.py \
    --data output/chemical_data.json \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --output-dir trained_model/chemical \
    --learning-rate 1e-4 \
    --epochs 3
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
```bash
# –ë–∞–∑–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --questions \
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞—Å–æ—Å?" \
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –¥–∏—Å–ø–µ—Ä–≥–∞—Ç–æ—Ä?" \
        "–ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å?"

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v1 \
    --questions \
        "–û–±—ä—è—Å–Ω–∏—Ç–µ –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã —à–∞—Ä–æ–≤–æ–π –º–µ–ª—å–Ω–∏—Ü—ã" \
        "–ö–∞–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∫—Ä–µ–ø–∏?" \
    --max-length 300 \
    --temperature 0.7
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –≥–æ—Ä–Ω–æ–º –¥–µ–ª–µ
```bash
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏ –ø–æ –≥–æ—Ä–Ω–æ–º—É –¥–µ–ª—É
python app/compare_models.py \
    --base-model models/qwen-2.5-3b \
    --trained-model trained_model/v3_continued \
    --questions \
        "–ö–∞–∫–∏–µ —Ç–∏–ø—ã –≥–æ—Ä–Ω—ã—Ö –≤—ã—Ä–∞–±–æ—Ç–æ–∫ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –ø–æ–¥–∑–µ–º–Ω–æ–π –¥–æ–±—ã—á–µ?" \
        "–ö–∞–∫ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫—Ä–µ–ø–æ—Å—Ç–∏ –ü—Ä–æ—Ç–æ–¥—å—è–∫–æ–Ω–æ–≤–∞?" \
        "–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—ä—è–≤–ª—è—é—Ç—Å—è –∫ –≥–æ—Ä–Ω–æ–π –∫—Ä–µ–ø–∏?" \
        "–ö–∞–∫ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —É–¥–µ–ª—å–Ω—ã–π —Ä–∞—Å—Ö–æ–¥ –≤–∑—Ä—ã–≤—á–∞—Ç—ã—Ö –≤–µ—â–µ—Å—Ç–≤?" \
        "–ö–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø—Ä–æ–≤–µ—Ç—Ä–∏–≤–∞–Ω–∏—è –≤—ã—Ä–∞–±–æ—Ç–æ–∫?" \
    --max-length 300
```

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

### üì¶ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

#### **–ü—É–±–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏)**
- **Qwen 2.5 3B** - `Qwen/Qwen2.5-3B-Instruct` (~6GB)
- **Mistral 7B** - `mistralai/Mistral-7B-Instruct-v0.2` (~14GB)
- **YandexGPT 5 Lite 8B** - `yandex/YandexGPT-5-Lite-8B-instruct` (~16GB)

#### **–ú–æ–¥–µ–ª–∏ —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π**
- **Llama 2** - `meta-llama/Llama-2-7b-chat-hf` (—Ç—Ä–µ–±—É–µ—Ç —Ç–æ–∫–µ–Ω)
- **CodeLlama** - `codellama/CodeLlama-7b-Instruct-hf`

### üöÄ –ë—ã—Å—Ç—Ä–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π

#### **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**
```bash
# –°–∫—Ä–∏–ø—Ç –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
./install_models.sh
```

#### **–†—É—á–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞**
```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å git-lfs
sudo apt-get install git-lfs
git lfs install

# 2. –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏
git clone https://huggingface.co/Qwen/Qwen2.5-3B-Instruct models/qwen-2.5-3b
git clone https://huggingface.co/yandex/YandexGPT-5-Lite-8B-instruct models/yandex-model

# 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–∫—É
ls -la models/
```

### üíæ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–∏—Å–∫–æ–≤–æ–º—É –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤—É

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π GPU |
|--------|--------|-------------------|
| Qwen 2.5 3B | ~6GB | 8GB+ |
| YandexGPT 5 Lite 8B | ~16GB | 16GB+ |
| Mistral 7B | ~14GB | 16GB+ |
| Llama 2 7B | ~13GB | 16GB+ |

### üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤

#### **–ú–æ—â–Ω—ã–π —Å–µ—Ä–≤–µ—Ä (GPU 16GB+)**
```bash
# –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –º–æ–¥–µ–ª–∏
python app/train_qlora.py \
    --base-model models/yandex-model \
    --batch-size 4 \
    --lora-r 16
```

#### **–°—Ä–µ–¥–Ω–∏–π —Å–µ—Ä–≤–µ—Ä (GPU 8GB)**
```bash
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Qwen 2.5 3B
python app/train_qlora.py \
    --base-model models/qwen-2.5-3b \
    --batch-size 2 \
    --lora-r 8
```

#### **–°–ª–∞–±—ã–π —Å–µ—Ä–≤–µ—Ä (CPU —Ç–æ–ª—å–∫–æ)**
```bash
# –û—Ç–∫–ª—é—á–∏—Ç—å GPU
export CUDA_VISIBLE_DEVICES=""

python app/train_qlora.py \
    --base-model models/qwen-2.5-3b \
    --batch-size 1 \
    --lora-r 4 \
    --epochs 1
```

## ‚öôÔ∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **Python** 3.8+
- **PyTorch** 2.0+
- **Transformers** 4.30+
- **PEFT** (Parameter-Efficient Fine-Tuning)
- **Git LFS** –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
- **GPU** —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- **RAM** –º–∏–Ω–∏–º—É–º 16GB
- **–î–∏—Å–∫** –º–∏–Ω–∏–º—É–º 50GB –¥–ª—è –º–æ–¥–µ–ª–µ–π

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
- **LoRA Rank**: 4-64 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 16)
- **Learning Rate**: 1e-5 –¥–æ 2e-4
- **Batch Size**: 1-16 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç GPU)
- **Epochs**: 1-10 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏)

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ –º–æ–¥–µ–ª–∏

#### **Qwen 2.5 3B**
```bash
--epochs 3 --learning-rate 2e-4 --batch-size 2 --lora-r 16
```

#### **YandexGPT 5 Lite 8B**
```bash
--epochs 2 --learning-rate 1e-4 --batch-size 1 --lora-r 8
```

#### **Mistral 7B**
```bash
--epochs 2 --learning-rate 1e-4 --batch-size 1 --lora-r 8
```

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

- **–ö–æ–Ω—Å–æ–ª—å–Ω—ã–µ –ª–æ–≥–∏** –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- **–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** –º–æ–¥–µ–ª–µ–π –∫–∞–∂–¥—ã–µ 100 —à–∞–≥–æ–≤
- **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞** –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ

## üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —É–ª—É—á—à–µ–Ω–∏—è

### ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### **–û—à–∏–±–∫–∞ "element 0 of tensors does not require_grad"**
- ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Qwen –º–æ–¥–µ–ª–µ–π –≤ `target_modules`
- ‚úÖ –í–∫–ª—é—á–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞ –æ–±—É—á–µ–Ω–∏—è (`model.train()`) –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è LoRA
- ‚úÖ –û—Ç–∫–ª—é—á–µ–Ω–∏–µ `use_cache` –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å gradient checkpointing
- ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ trainable –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º

#### **–ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –æ–±—É—á–µ–Ω–∏—è**
- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ —Å `is_trainable=True`
- ‚úÖ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –≤–∫–ª—é—á–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—Å–µ—Ö LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö trainable –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

#### **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏**
- ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CUDA –¥–ª—è –ª—É—á—à–µ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é
- ‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤ OpenMP, MKL, NumExpr
- ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Å —ç–∫–æ–Ω–æ–º–∏–µ–π –ø–∞–º—è—Ç–∏

## üö® –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø–æ–ª–∞–¥–æ–∫

### –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∞–º—è—Ç–∏ GPU**
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å batch-size –∏ lora-r
python app/train_qlora.py --batch-size 1 --lora-r 4

# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CPU
export CUDA_VISIBLE_DEVICES=""
```

#### **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM**
```bash
# –£–º–µ–Ω—å—à–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
python app/train_qlora.py --epochs 1 --batch-size 1 --lora-r 4
```

#### **–û—à–∏–±–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å git-lfs
git lfs install

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ Hugging Face
curl -I https://huggingface.co/Qwen/Qwen2.5-3B-Instruct
```

#### **–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU: `nvidia-smi`
- –£–≤–µ–ª–∏—á—å—Ç–µ batch-size –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –º–æ—â–Ω—ã–π —Å–µ—Ä–≤–µ—Ä

#### **–ü—Ä–æ–±–ª–µ–º—ã —Å Ollama**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å Ollama
ollama list

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å Ollama
sudo systemctl restart ollama

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
curl http://localhost:11434/api/tags
```

### –ü–æ–¥–¥–µ—Ä–∂–∫–∞
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤ –∫–æ–Ω—Å–æ–ª–∏
- –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫
- –í—Å–µ —Å–∫—Ä–∏–ø—Ç—ã —Ç–µ–ø–µ—Ä—å –∏–º–µ—é—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

## ü§ù –í–∫–ª–∞–¥ –≤ –ø—Ä–æ–µ–∫—Ç

1. –§–æ—Ä–∫–Ω–∏—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
2. –°–æ–∑–¥–∞–π—Ç–µ –≤–µ—Ç–∫—É –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
3. –í–Ω–µ—Å–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –°–æ–∑–¥–∞–π—Ç–µ Pull Request

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π MIT.

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- Hugging Face –∑–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Transformers –∏ PEFT
- Microsoft –∑–∞ LoRA –º–µ—Ç–æ–¥
- Alibaba Cloud –∑–∞ –º–æ–¥–µ–ª—å Qwen
- Yandex –∑–∞ –º–æ–¥–µ–ª—å YandexGPT
- –°–æ–æ–±—â–µ—Å—Ç–≤–æ open-source –∑–∞ –≤–∫–ª–∞–¥ –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ

---

**SuperApp** - –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–µ–µ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å –ø–æ–º–æ—â—å—é AI! üöÄ
