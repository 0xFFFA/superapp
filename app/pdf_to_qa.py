#!/usr/bin/env python3
"""
PDF to Q&A Dataset Generator
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ PDF —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
"""

import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Optional
import requests
import time
import urllib3

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

try:
    import PyPDF2
    import pdfplumber
except ImportError:
    print("–û—à–∏–±–∫–∞: –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyPDF2 –∏ pdfplumber")
    print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install PyPDF2 pdfplumber")
    sys.exit(1)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç-—à–∞–±–ª–æ–Ω—ã
from prompt_templates import PromptTemplates, validate_qa_quality


class PDFToQAGenerator:
    def __init__(self, ollama_url: str = "http://localhost:11434", model: str = "llama3.1:8b", api_token: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        
        Args:
            ollama_url: URL –¥–ª—è Ollama API
            model: –ú–æ–¥–µ–ª—å Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            api_token: –¢–æ–∫–µ–Ω –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è Ollama
        """
        self.ollama_url = ollama_url
        self.model = model
        self.api_token = api_token
        self.max_chunk_size = 4000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –±–ª–æ–∫–∞ –¥–ª—è Ollama
        
    def read_pdf(self, pdf_path: str) -> str:
        """
        –ß–∏—Ç–∞–µ—Ç PDF —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç
        
        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
            
        Returns:
            –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        print(f"–ß–∏—Ç–∞—é PDF —Ñ–∞–π–ª: {pdf_path}")
        
        try:
            # –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ pdfplumber –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            with pdfplumber.open(pdf_path) as pdf:
                text = ""
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                        
            if not text.strip():
                # Fallback –∫ PyPDF2 –µ—Å–ª–∏ pdfplumber –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
                with open(pdf_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    text = ""
                    for page in pdf_reader.pages:
                        text += page.extract_text() + "\n"
                        
            if not text.strip():
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF")
                
            print(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return text.strip()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF: {e}")
            raise
    
    def split_text_into_chunks(self, text: str) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤
        """
        print("–†–∞–∑–±–∏–≤–∞—é —Ç–µ–∫—Å—Ç –Ω–∞ –±–ª–æ–∫–∏...")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
        
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –±–ª–æ–∫ + –Ω–æ–≤—ã–π –∞–±–∑–∞—Ü –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç
            if len(current_chunk) + len(paragraph) > self.max_chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = paragraph
                else:
                    # –ï—Å–ª–∏ –æ–¥–∏–Ω –∞–±–∑–∞—Ü —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ
                    if len(paragraph) > self.max_chunk_size:
                        words = paragraph.split()
                        temp_chunk = ""
                        for word in words:
                            if len(temp_chunk) + len(word) + 1 <= self.max_chunk_size:
                                temp_chunk += word + " "
                            else:
                                if temp_chunk:
                                    chunks.append(temp_chunk.strip())
                                temp_chunk = word + " "
                        current_chunk = temp_chunk
                    else:
                        current_chunk = paragraph
            else:
                current_chunk += "\n\n" + paragraph if current_chunk else paragraph
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        print(f"–°–æ–∑–¥–∞–Ω–æ {len(chunks)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤")
        return chunks
    

    

    
    def generate_qa_pairs(self, text_chunk: str, num_questions: int, error_log_path: str = None) -> List[Dict[str, str]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –±–ª–æ–∫–∞
        
        Args:
            text_chunk: –¢–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
            num_questions: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
            error_log_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—à–∏–±–æ–∫
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏
        """
        return self._make_ollama_request(text_chunk, num_questions, error_log_path)
    

    
    def _make_ollama_request(self, text_chunk: str, num_questions: int, error_log_path: str = None) -> List[Dict[str, str]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Ollama API —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        
        Args:
            text_chunk: –¢–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
            num_questions: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ PromptTemplates
        prompt = PromptTemplates.get_qa_generation_prompt(text_chunk, num_questions)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –±–ª–æ–∫–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
        base_timeout = 120
        size_factor = len(text_chunk) // 1000 * 30  # +30 —Å–µ–∫ –Ω–∞ –∫–∞–∂–¥—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤
        questions_factor = num_questions * 15  # +15 —Å–µ–∫ –Ω–∞ –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
        adaptive_timeout = min(600, base_timeout + size_factor + questions_factor)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        headers = {}
        if self.api_token:
            headers['X-Access-Token'] = self.api_token
        
        response = requests.post(
            f"{self.ollama_url}/api/generate",
            headers=headers,
            json={
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9
                }
            },
            timeout=adaptive_timeout,
            verify=False  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É SSL –¥–ª—è —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã—Ö —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤
        )
        
        if response.status_code == 200:
            result = response.json()
            response_text = result.get('response', '')
            
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
            try:
                # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown –±–ª–æ–∫–æ–≤ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                cleaned_response = response_text.strip()
                if cleaned_response.startswith('```json'):
                    # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏
                    cleaned_response = cleaned_response.replace('```json', '').replace('```', '').strip()
                elif cleaned_response.startswith('```'):
                    # –£–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ markdown –±–ª–æ–∫–∏
                    cleaned_response = cleaned_response.replace('```', '').strip()
                
                parsed_data = json.loads(cleaned_response)
                print(f"üîç –¢–∏–ø –æ—Ç–≤–µ—Ç–∞: {type(parsed_data)}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π —Å –ø–æ–ª–µ–º "questions"
                if isinstance(parsed_data, dict):
                    if "questions" in parsed_data:
                        qa_pairs = parsed_data["questions"]
                        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ 'questions' —Å {len(qa_pairs)} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏")
                    else:
                        print(f"‚ö†Ô∏è  –°–ª–æ–≤–∞—Ä—å –±–µ–∑ –ø–æ–ª—è 'questions', –∫–ª—é—á–∏: {list(parsed_data.keys())}")
                        if error_log_path:
                            with open(error_log_path, 'a', encoding='utf-8') as f:
                                f.write(f"\n{'='*50}\n")
                                f.write(f"–°–ª–æ–≤–∞—Ä—å –±–µ–∑ –ø–æ–ª—è 'questions'\n")
                                f.write(f"–ö–ª—é—á–∏: {list(parsed_data.keys())}\n")
                                f.write(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{response_text}\n")
                        return []
                else:
                    qa_pairs = parsed_data
                    print(f"‚úÖ –ü—Ä—è–º–æ–π –º–∞—Å—Å–∏–≤ —Å {len(qa_pairs)} —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if isinstance(qa_pairs, list) and all(
                    isinstance(qa, dict) and 'question' in qa and 'answer' in qa 
                    for qa in qa_pairs
                ):
                    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
                    validated_pairs = []
                    for qa in qa_pairs:
                        validation = validate_qa_quality(qa['question'], qa['answer'])
                        if validation['passed']:
                            validated_pairs.append(qa)
                        else:
                            print(f"‚ö†Ô∏è  –ü–∞—Ä–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–∞ (–æ—Ü–µ–Ω–∫–∞ {validation['quality_score']}/10): {qa['question'][:50]}...")
                            if error_log_path:
                                self._log_quality_issue(error_log_path, qa, validation)
                    
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(qa_pairs)} –ø–∞—Ä, {len(validated_pairs)} –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–∞—á–µ—Å—Ç–≤–∞")
                    return validated_pairs
                else:
                    print("‚ö†Ô∏è  –ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")
                    if error_log_path:
                        with open(error_log_path, 'a', encoding='utf-8') as f:
                            f.write(f"\n{'='*50}\n")
                            f.write(f"–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n")
                            f.write(f"–¢–∏–ø: {type(qa_pairs)}\n")
                            f.write(f"–î–∞–Ω–Ω—ã–µ: {qa_pairs}\n")
                            f.write(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{response_text}\n")
                    return []
                    
            except json.JSONDecodeError as e:
                print("‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON")
                if error_log_path:
                    with open(error_log_path, 'a', encoding='utf-8') as f:
                        f.write(f"\n{'='*50}\n")
                        f.write(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}\n")
                        f.write(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{response_text}\n")
                return []
        else:
            print(f"–û—à–∏–±–∫–∞ API Ollama: {response.status_code}")
            return []
    
    def _log_quality_issue(self, error_log_path: str, qa_pair: Dict, validation: Dict):
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            error_log_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤
            qa_pair: –ü–∞—Ä–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
            validation: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        try:
            with open(error_log_path, 'a', encoding='utf-8') as f:
                f.write(f"\n{'='*50}\n")
                f.write(f"–ü–†–û–ë–õ–ï–ú–ê –ö–ê–ß–ï–°–¢–í–ê –î–ê–ù–ù–´–•\n")
                f.write(f"–û—Ü–µ–Ω–∫–∞: {validation['quality_score']}/10\n")
                f.write(f"–ü—Ä–æ–±–ª–µ–º—ã: {', '.join(validation['issues'])}\n")
                f.write(f"–í–æ–ø—Ä–æ—Å: {qa_pair['question']}\n")
                f.write(f"–û—Ç–≤–µ—Ç: {qa_pair['answer']}\n")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ª–æ–≥: {e}")
    
    def process_pdf(self, pdf_path: str, output_path: str, questions_per_chunk: int = 3) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF –∏ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        
        Args:
            pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            questions_per_chunk: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            # –ß–∏—Ç–∞–µ–º PDF
            text = self.read_pdf(pdf_path)
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–ª–æ–∫–∏
            chunks = self.split_text_into_chunks(text)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
            all_qa_pairs = []
            
            # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—à–∏–±–æ–∫
            error_log_path = output_path.replace('.json', '.err')
            
            for i, chunk in enumerate(chunks):
                print(f"\n–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–ª–æ–∫ {i+1}/{len(chunks)}")
                qa_pairs = self.generate_qa_pairs(chunk, questions_per_chunk, error_log_path)
                all_qa_pairs.extend(qa_pairs)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                if i < len(chunks) - 1:
                    time.sleep(1)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if all_qa_pairs:
                output_data = {
                    "source_pdf": pdf_path,
                    "total_questions": len(all_qa_pairs),
                    "generation_date": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "model_used": self.model,
                    "qa_pairs": all_qa_pairs
                }
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2)
                
                print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω –¥–∞—Ç–∞—Å–µ—Ç!")
                print(f"üìä –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(all_qa_pairs)}")
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_path}")
                return True
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF: {e}")
            return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ PDF —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama"
    )
    parser.add_argument("pdf_path", help="–ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É")
    parser.add_argument("-o", "--output", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output.json)")
    parser.add_argument("-m", "--model", default="llama3.1:8b", help="–ú–æ–¥–µ–ª—å Ollama (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: llama3.1:8b)")
    parser.add_argument("-q", "--questions", type=int, default=3, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)")
    parser.add_argument("--ollama-url", default="http://localhost:11434", help="URL Ollama API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: http://localhost:11434)")
    parser.add_argument("--api-token", help="–¢–æ–∫–µ–Ω –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è Ollama API")
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ PDF —Ñ–∞–π–ª–∞
    if not os.path.exists(args.pdf_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.pdf_path}")
        sys.exit(1)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    if args.output:
        output_path = args.output
    else:
        pdf_name = Path(args.pdf_path).stem
        output_path = f"{pdf_name}_qa_dataset.json"
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å–æ–≤-–æ—Ç–≤–µ—Ç–æ–≤")
    print(f"üìÅ PDF —Ñ–∞–π–ª: {args.pdf_path}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {args.model}")
    print(f"‚ùì –í–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞ –±–ª–æ–∫: {args.questions}")
    print(f"üíæ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
    print("-" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    generator = PDFToQAGenerator(
        ollama_url=args.ollama_url,
        model=args.model,
        api_token=args.api_token
    )
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º PDF
    success = generator.process_pdf(
        pdf_path=args.pdf_path,
        output_path=output_path,
        questions_per_chunk=args.questions
    )
    
    if success:
        print("\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        sys.exit(0)
    else:
        print("\nüí• –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        sys.exit(1)


if __name__ == "__main__":
    main()
